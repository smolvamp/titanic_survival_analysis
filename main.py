"""
Main orchestration script for Titanic dataset preprocessing.

This script coordinates all preprocessing steps in the correct order.
"""

from src.load_data import load_titanic_data
from src.inspect import inspect_dataset
from src.clean import clean_missing_values, drop_irrelevant_columns, check_duplicates
from src.feature_engineering import create_new_features
from src.encode import encode_categorical_variables
from src.outliers import handle_outliers
from src.normalize import normalize_features
from src.visualize import create_visualizations
from src.summary import generate_summary_statistics
from src.export import export_cleaned_dataset


def main():
    """Execute the complete Titanic dataset preprocessing pipeline."""
    print("=" * 60)
    print("TITANIC DATASET PREPROCESSING PIPELINE")
    print("=" * 60)
    
    # Step 1: Load the dataset
    df = load_titanic_data('data/train.csv')
    if df is None:
        print("âŒ Failed to load dataset. Exiting.")
        return
    
    # Step 2: Initial inspection
    inspect_dataset(df)
    
    # Step 3: Clean missing values
    df = clean_missing_values(df)
    
    # Step 4: Drop irrelevant columns
    df = drop_irrelevant_columns(df)
    
    # Step 5: Check for duplicates
    df = check_duplicates(df)
    
    # Step 6: Feature engineering
    df = create_new_features(df)
    
    # Step 7: Encode categorical variables
    df, encoders = encode_categorical_variables(df)
    
    # Step 8: Handle outliers
    df = handle_outliers(df)
    
    # Step 9: Normalize features
    df, scaler = normalize_features(df)
    
    # Step 10: Create visualizations
    create_visualizations(df, 'data/train.csv')
    
    # Step 11: Generate summary statistics
    generate_summary_statistics(df, 'data/train.csv')
    
    # Step 12: Export cleaned dataset
    export_cleaned_dataset(df, 'titanic_cleaned.csv')
    
    # Final summary
    print("\n" + "=" * 60)
    print("PREPROCESSING COMPLETED SUCCESSFULLY! ğŸ‰")
    print("=" * 60)
    
    print("\nğŸ“‹ PROCESSING SUMMARY:")
    print("âœ“ Dataset loaded and inspected")
    print("âœ“ Missing values handled")
    print("âœ“ Irrelevant columns removed")
    print("âœ“ Duplicates checked")
    print("âœ“ New features engineered")
    print("âœ“ Categorical variables encoded")
    print("âœ“ Outliers identified and handled")
    print("âœ“ Numerical features normalized")
    print("âœ“ Comprehensive visualizations created")
    print("âœ“ Summary statistics generated")
    print("âœ“ Cleaned dataset exported")
    
    print("\nğŸ“ FILES CREATED:")
    print("â€¢ titanic_cleaned.csv - Cleaned and processed dataset")
    print("â€¢ correlation_heatmap.png - Feature correlation visualization")
    print("â€¢ distribution_plots.png - Feature distribution plots")
    print("â€¢ categorical_plots.png - Categorical variable visualizations")
    print("â€¢ outlier_boxplots.png - Outlier detection plots")
    
    print(f"\nğŸ¯ FINAL DATASET SHAPE: {df.shape}")
    print(f"ğŸ“Š FEATURES READY FOR ANALYSIS: {len(df.columns)}")
    
    print("\n" + "=" * 60)
    print("The dataset is now ready for machine learning modeling!")
    print("=" * 60)


if __name__ == "__main__":
    main()
